{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Object detection and Threshold/Occupancy maker.."
      ],
      "metadata": {
        "id": "Ga3C_jIQzlfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object detection"
      ],
      "metadata": {
        "id": "ljNE2U6N0tJy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro6wI3LUxHA7",
        "outputId": "d75b8274-af8d-4ad3-c3e0-7bcc4f0ef976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'pillow>=10.3.0', 'requests>=2.32.0'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.3/207.3 kB 6.6 MB/s eta 0:00:00\n",
            "Collecting pillow>=10.3.0\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.5/4.5 MB 29.0 MB/s eta 0:00:00\n",
            "Collecting requests>=2.32.0\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 64.9/64.9 kB 185.2 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 175.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0) (2024.7.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, requests, pillow, gitdb, gitpython\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pillow-10.4.0 requests-2.32.3 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 8.9s, installed 3 packages: ['gitpython>=3.1.30', 'pillow>=10.3.0', 'requests>=2.32.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ 2024-7-13 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n",
            "WARNING âš ï¸ NMS time limit 0.550s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displayed image saved locally as output_image_0.png\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model_path = 'best.pt'  # Model\n",
        "\n",
        "# Check if the model file exists\n",
        "if not Path(model_path).exists():\n",
        "    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
        "\n",
        "# Load the model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
        "\n",
        "# Load an image\n",
        "img_path = 'saved_images/output/stitched_image_output.png'\n",
        "if not Path(img_path).exists():\n",
        "    raise FileNotFoundError(f\"Image file not found at {img_path}\")\n",
        "\n",
        "# Perform inference / Prediction\n",
        "results = model(img_path)\n",
        "\n",
        "\n",
        "def render_without_labels(results):\n",
        "    for i, (im, pred) in enumerate(zip(results.ims, results.pred)): # Use results.ims instead of results.imgs\n",
        "        if pred is not None:\n",
        "            for *box, conf, cls in reversed(pred):  # xyxy, confidence, class\n",
        "                label = f'{results.names[int(cls)]} {conf:.2f}' if conf > 0 else f'{results.names[int(cls)]}'\n",
        "                # Remove label and confidence display\n",
        "                # Make below comment line executable to get object namings\n",
        "                # cv2.putText(im, label, (int(box[0]), int(box[1]) - 2), 0, 0.6, [225, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n",
        "                cv2.rectangle(im, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 0, 0), -1)\n",
        "        yield im\n",
        "\n",
        "displayed_image_np = list(render_without_labels(results))\n",
        "\n",
        "# Save the results\n",
        "for i, img_np in enumerate(displayed_image_np):\n",
        "    output_image_path = f'output_image_{i}.png'\n",
        "    cv2.imwrite(output_image_path, img_np)\n",
        "    print(f\"Displayed image saved locally as {output_image_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal png creator"
      ],
      "metadata": {
        "id": "DOPW7a5k0yAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Marked\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to apply thresholding to an image\n",
        "def apply_threshold(image, threshold_value):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresholded_image = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "    return thresholded_image\n",
        "\n",
        "\n",
        "# Define threshold value (adjust as needed)\n",
        "threshold_value = 150\n",
        "\n",
        "# Apply thresholding to each displayed image and save\n",
        "for i, img_np in enumerate(displayed_image_np):\n",
        "    thresholded_img = apply_threshold(img_np, threshold_value)\n",
        "    output_image_path = f'output_image_{i}_thresholded.png'\n",
        "    cv2.imwrite(output_image_path, thresholded_img)\n",
        "    print(f\"Thresholded image saved locally as {output_image_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB6LKn2sxc4U",
        "outputId": "e600b655-bfc6-436e-b7ea-c2b1979ba463"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholded image saved locally as output_image_0_thresholded.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Occcupancy grid maker with 512x512 resolution and with .pgm extension"
      ],
      "metadata": {
        "id": "IG_ObIIi02ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Function to apply thresholding to an image\n",
        "def apply_threshold(image, threshold_value):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresholded_image = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "    return thresholded_image\n",
        "\n",
        "# Function to resize an image to 512x512 resolution\n",
        "def resize_image(image, width, height):\n",
        "    return cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Assuming you have `displayed_image_np` from your previous code\n",
        "# displayed_image_np = []  # Placeholder for your list of images\n",
        "\n",
        "# Define threshold value (adjust as needed)\n",
        "threshold_value = 150\n",
        "\n",
        "# Desired output resolution\n",
        "output_width = 512\n",
        "output_height = 512\n",
        "\n",
        "# Apply thresholding, resize and save each displayed image\n",
        "for i, img_np in enumerate(displayed_image_np):\n",
        "    # Start timing\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Apply thresholding\n",
        "    thresholded_img = apply_threshold(img_np, threshold_value)\n",
        "\n",
        "    # Resize to 512x512\n",
        "    resized_img = resize_image(thresholded_img, output_width, output_height)\n",
        "\n",
        "    # Save as .pgm file\n",
        "    output_image_path = f'output_image_{i}_thresholded.pgm'\n",
        "    cv2.imwrite(output_image_path, resized_img)\n",
        "\n",
        "    # End timing\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate elapsed time\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Thresholded image saved locally as {output_image_path} in {elapsed_time:.4f} seconds\")\n",
        "\n",
        "print(\"All images have been processed and saved.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbOGWC6JyccP",
        "outputId": "d3734b58-cccd-401b-9b18-f995a54ed7c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thresholded image saved locally as output_image_0_thresholded.pgm in 0.0079 seconds\n",
            "All images have been processed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2CG5f1qK1pxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
